<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Socious Translator</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    body { font-family: 'Inter', 'Helvetica Neue', sans-serif; }
    .caret::after { content: ' ▌'; opacity: 0.6; }
    /* Make the output look like one flowing paragraph */
    #committed { display: block; white-space: normal; line-height: 1.6; word-break: break-word; }
    #committed .seg::after { content: " "; } /* space between segments */
  </style>
</head>
<body class="bg-[#111112] text-white min-h-screen flex flex-col items-center justify-start p-6 space-y-10">

  <h1 class="text-3xl font-bold tracking-tight text-center">Socious Translator</h1>

  <!-- Controls -->
  <div class="w-full max-w-3xl bg-[#1A1A1C] rounded-2xl p-6 shadow-lg flex flex-col items-center space-y-6">
    <div class="w-full flex flex-col lg:flex-row lg:items-end lg:justify-center lg:gap-6 space-y-4 lg:space-y-0">
      <div class="flex flex-col w-full lg:w-auto items-center">
        <label for="direction" class="text-base font-medium mb-1">Translation Direction</label>
        <select id="direction" class="w-full lg:w-64 bg-[#2A2A2E] text-white border border-gray-700 rounded px-4 py-2 focus:outline-none text-center">
          <option value="en-ja">English → Japanese</option>
          <option value="ja-en">Japanese → English</option>
        </select>
      </div>
      <div class="flex flex-col sm:flex-row gap-4">
        <button id="startBtn" class="bg-gray-700 hover:bg-gray-600 text-white font-semibold px-6 py-2 rounded transition-all">Start Recording</button>
        <button id="stopBtn" disabled class="bg-gray-500 text-white font-semibold px-6 py-2 rounded opacity-50 cursor-not-allowed">Stop Recording</button>
      </div>
    </div>
    <div id="status" class="text-sm text-gray-400"></div>
  </div>

  <!-- Output -->
  <div class="w-full max-w-4xl flex flex-col space-y-6 items-center">
    <div class="w-full">
      <div id="output" class="bg-[#1A1A1C] rounded-lg px-6 py-10 shadow-md text-2xl font-semibold leading-8 tracking-wide min-h-[160px] w-full">
        <div id="committed"></div>
        <div id="active" class="caret mt-3 text-white"></div>
      </div>
    </div>
  </div>

  <script>
    const startBtn = document.getElementById("startBtn");
    const stopBtn = document.getElementById("stopBtn");
    const directionSelect = document.getElementById("direction");
    const committed = document.getElementById("committed");
    const active = document.getElementById("active");
    const statusEl = document.getElementById("status");

    let mediaStream = null;
    let socket = null;
    let recording = false;

    const MAX_CHARS = 400; // cap the paragraph length for live readability

    // FIXED: use a template literal for WebSocket URL
    function wsUrl() {
      const proto = location.protocol === "https:" ? "wss" : "ws";
      return `${proto}://${location.host}/ws`;
    }

    directionSelect.onchange = () => stopRecording();

    function setButtons(running) {
      startBtn.disabled = running;
      stopBtn.disabled = !running;
      startBtn.classList.toggle("opacity-50", running);
      startBtn.classList.toggle("cursor-not-allowed", running);
      stopBtn.classList.toggle("opacity-50", !running);
      stopBtn.classList.toggle("cursor-not-allowed", !running);
    }

    function setStatus(text) {
      statusEl.textContent = text || "";
    }

    function setActivePartial(text) {
      active.textContent = text || "";
      active.classList.toggle("caret", !!text);
    }

    function clearActivePartial() {
      setActivePartial("");
    }

    function totalChars() {
      return committed.innerText.length;
    }

    function trimToMaxChars() {
      // Remove oldest segments until under MAX_CHARS
      while (totalChars() > MAX_CHARS && committed.firstElementChild) {
        committed.removeChild(committed.firstElementChild);
      }
    }

    function commitFinal(text, id = null) {
      const span = document.createElement("span");
      span.className = "seg";
      if (id) span.dataset.id = id;
      span.textContent = (text || "").trim();
      committed.appendChild(span);
      trimToMaxChars();
      // Auto-scroll to bottom
      window.requestAnimationFrame(() => {
        window.scrollTo({ top: document.body.scrollHeight, behavior: "smooth" });
      });
    }

    // Backend only sends [DONE] and [UPDATE]
    function handleMessage(data) {
      try {
        if (typeof data !== "string") return;
        if (data.startsWith("[DONE]")) {
          const { id, text } = JSON.parse(data.replace("[DONE]", ""));
          clearActivePartial();
          commitFinal(text || "", id);
          return;
        }
        if (data.startsWith("[UPDATE]")) {
          const { id, text } = JSON.parse(data.replace("[UPDATE]", ""));
          if (id) {
            // FIXED: valid selector string
            const target = committed.querySelector(`[data-id="${id}"]`);
            if (target) {
              target.textContent = (text || "").trim();
              trimToMaxChars();
            }
          }
          return;
        }
        // Ignore any other message types
      } catch (e) {
        console.warn("Message parse error:", e);
      }
    }

    async function startRecording() {
      try {
        // Feature checks
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          throw new Error("getUserMedia is not available in this browser/context.");
        }
        if (!("MediaRecorder" in window)) {
          throw new Error("MediaRecorder API not supported in this browser.");
        }

        const preferred = [
          "audio/ogg;codecs=opus",
          "audio/webm;codecs=opus",
          "audio/webm"
        ];
        let mimeType = "";
        for (const t of preferred) {
          try {
            if (MediaRecorder.isTypeSupported(t)) { mimeType = t; break; }
          } catch { /* older browsers may throw; ignore */ }
        }
        if (!mimeType) {
          throw new Error("No supported audio MIME type (WebM/Opus) found.");
        }

        // (Optional) surface current permission state where supported
        if (navigator.permissions && navigator.permissions.query) {
          try {
            const p = await navigator.permissions.query({ name: "microphone" });
            setStatus(`Microphone permission: ${p.state}`);
          } catch { /* permissions API not available */ }
        }

        // This is where the prompt should appear
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });

        setStatus("Connecting…");
        socket = new WebSocket(wsUrl());

        socket.onopen = () => {
          try {
            socket.send(JSON.stringify({ direction: directionSelect.value }));
          } catch {}
          recording = true;
          setButtons(true);
          setStatus("Recording…");
          recordLoop(mimeType);
        };

        socket.onmessage = (e) => handleMessage(e.data);

        socket.onclose = () => {
          setButtons(false);
          setActivePartial("");
          setStatus("Disconnected");
          recording = false; // ensure loop stops if socket drops
        };

        socket.onerror = (e) => {
          console.error("WebSocket error:", e);
          setStatus("WebSocket error");
        };

      } catch (err) {
        console.error("Error starting recording:", err);
        setStatus(
          (err && err.name) ? `Mic error: ${err.name}` :
          (err && err.message) ? `Mic error: ${err.message}` :
          "Mic error"
        );
        stopRecording();
      }
    }

    async function recordLoop(mimeType) {
      let recorder;
      try {
        recorder = new MediaRecorder(mediaStream, { mimeType });
      } catch (e) {
        console.error("Failed to create MediaRecorder:", e);
        setStatus("Failed to create MediaRecorder");
        stopRecording();
        return;
      }

      let chunks = [];
      let totalBytes = 0;
      let isFlushPending = false;
      let flushTimer = null;
      let forceDataTimer = null;
      let lastSuccessfulSend = performance.now();
      const TARGET_CHUNK_DURATION = 2000; // 2s chunks for lower latency
      const MAX_CHUNK_DURATION = 4000;    // 4s max before force flush
      const FORCE_DATA_INTERVAL = 1500;   // Force data extraction every 1.5s

      // Unified flush function with mutex
      async function flush(reason = "periodic") {
        if (isFlushPending || !chunks.length) return;

        // Check WebSocket state first
        if (socket?.readyState !== WebSocket.OPEN) {
          console.warn(`Flush skipped (${reason}): WebSocket not open`);
          // Keep data for potential reconnection instead of discarding
          return;
        }

        isFlushPending = true;
        const chunksCopy = [...chunks];
        const bytesCopy = totalBytes;

        try {
          const blob = new Blob(chunksCopy, { type: chunksCopy[0]?.type || mimeType });
          const buf = await blob.arrayBuffer();

          console.log(`Flushing ${chunksCopy.length} chunks (${bytesCopy} bytes) - reason: ${reason}`);
          socket.send(buf);

          // Only clear on successful send
          chunks = [];
          totalBytes = 0;
          lastSuccessfulSend = performance.now();

        } catch (err) {
          console.error("Failed to send audio:", err);
          setStatus("Audio send error - retrying");
          // Keep chunks for retry
        } finally {
          isFlushPending = false;
        }
      }

      // Schedule periodic flush
      function scheduleFlush() {
        if (flushTimer) clearTimeout(flushTimer);
        flushTimer = setTimeout(() => {
          flush("timer");
          if (recording) scheduleFlush();
        }, TARGET_CHUNK_DURATION);
      }

      // Data available handler
      recorder.ondataavailable = (e) => {
        if (!e.data || e.data.size === 0) return;

        chunks.push(e.data);
        totalBytes += e.data.size;
        console.log(`Data available: ${e.data.size} bytes (total: ${totalBytes})`);

        // Immediate flush conditions
        const timeSinceLastSend = performance.now() - lastSuccessfulSend;
        if (totalBytes >= 150_000 || // 150KB threshold (lowered)
            timeSinceLastSend >= MAX_CHUNK_DURATION) {
          flush("threshold");
        }
      };

      // Error handler
      recorder.onerror = (e) => {
        console.error("MediaRecorder error:", e);
        setStatus("Recording error - restarting");
      };

      try {
        // Use shorter timeslice for more frequent data availability
        recorder.start(500); // 500ms timeslice (more aggressive)
        console.log("MediaRecorder started with 500ms timeslice");

        // Start periodic flush timer
        scheduleFlush();

        // Periodically force data extraction if MediaRecorder is buffering
        forceDataTimer = setInterval(() => {
          if (recorder.state === "recording" && !isFlushPending) {
            try {
              // requestData() forces MediaRecorder to produce a data chunk
              recorder.requestData();
              console.log("Forced data request");
            } catch (e) {
              console.warn("requestData failed:", e);
            }
          }
        }, FORCE_DATA_INTERVAL);

      } catch (e) {
        console.error("MediaRecorder start failed:", e);
        setStatus("MediaRecorder start failed");
        stopRecording();
        return;
      }

      // Monitor for stalls
      const stallMonitor = setInterval(() => {
        const timeSinceLastSend = performance.now() - lastSuccessfulSend;
        if (timeSinceLastSend > 8000 && recording) {
          console.warn(`No successful sends for ${(timeSinceLastSend/1000).toFixed(1)}s`);
          setStatus("Connection issue - check network");

          // Force flush attempt
          if (chunks.length > 0) {
            flush("stall-recovery");
          }
        }
      }, 2000);

      // Cleanup on stop
      await new Promise((resolve) => {
        recorder.addEventListener("stop", async () => {
          // Clear all timers
          if (flushTimer) clearTimeout(flushTimer);
          if (forceDataTimer) clearInterval(forceDataTimer);
          clearInterval(stallMonitor);

          // Final flush
          await flush("final");
          console.log("MediaRecorder stopped, final flush complete");
          resolve();
        }, { once: true });
      });
    }


    function stopRecording() {
      recording = false;
      try { mediaStream?.getTracks().forEach(t => t.stop()); } catch {}
      try { socket && socket.readyState === WebSocket.OPEN && socket.close(); } catch {}
      setActivePartial("");
      setButtons(false);
      // don't overwrite error messages
      if (!statusEl.textContent) setStatus("");
    }

    startBtn.onclick = startRecording;
    stopBtn.onclick = stopRecording;

    // Small UX niceties: warn if not secure context (no prompt will appear)
    if (location.protocol !== "https:" && location.hostname !== "localhost" && location.hostname !== "127.0.0.1") {
      setStatus("Tip: Microphone requires HTTPS or localhost.");
    }
  </script>
</body>
</html>